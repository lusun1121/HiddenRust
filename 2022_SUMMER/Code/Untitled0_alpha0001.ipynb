{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0_alpha0001.ipynb","provenance":[],"authorship_tag":"ABX9TyMSO4fWH8fasRbKiT2rzioa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTM-UtbdzHc8","executionInfo":{"status":"ok","timestamp":1656082774442,"user_tz":300,"elapsed":795,"user":{"displayName":"Lu Sun","userId":"12220989488268625125"}},"outputId":"77bf7741-1847-4175-f7a0-4fc0e8fddb26"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XaNc3CzypXo","executionInfo":{"status":"ok","timestamp":1656084269029,"user_tz":300,"elapsed":1494590,"user":{"displayName":"Lu Sun","userId":"12220989488268625125"}},"outputId":"be76c91a-0417-4226-ad60-393f909cc26d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reminder1: file group4_new_175.csv should be in the same file directory\n","Reminder2: the code will take almost 4 hours\n","->Date generation\n","[0.009243000000000001, 0.00022600000000000002, 0.0011639999999999999]\n","generate Q\n","generate dataset\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [01:04<00:00, 46.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["->Estimation1 x0 known, alpha =  1\n","[9.243 0.226 1.164] -1061.6541783039825\n","[9.243 0.226 1.164] -1061.6541783039825\n","[9.24300001 0.226      1.164     ] -1061.6541784105702\n","[9.243      0.22600001 1.164     ] -1061.6541782911233\n","[9.243      0.226      1.16400001] -1061.6541781812045\n","[2.09001538 1.08896082 9.40348669] -290274.9611787684\n","[8.52770154 0.31229608 1.98794867] -1417.0700640323587\n","[9.17147015 0.23462961 1.24639487] -1062.3984704968643\n","[9.22094037 0.22866135 1.18941037] -1061.4616764382286\n","[9.22094037 0.22866135 1.18941037] -1061.4616764382286\n","[9.22094039 0.22866135 1.18941037] -1061.4616764499456\n","[9.22094037 0.22866136 1.18941037] -1061.4616764368836\n","[9.22094037 0.22866135 1.18941039] -1061.4616764413954\n","[8.61646339 0.29682224 0.72928471] -1063.4706461440067\n","[9.15329867 0.23628863 1.13792176] -1061.4259421882773\n","[9.15329867 0.23628863 1.13792176] -1061.4259421882773\n","[9.15329869 0.23628863 1.13792176] -1061.4259421923634\n","[9.15329867 0.23628865 1.13792176] -1061.4259421930292\n","[9.15329867 0.23628863 1.13792178] -1061.4259421854078\n","[9.01464199e+00 1.00000000e-06 1.05654736e+00] -1061.4372699282733\n","[9.09117323 0.13041942 1.10146177] -1061.4040490212772\n","[9.09117323 0.13041942 1.10146177] -1061.4040490212772\n","[9.09117324 0.13041942 1.10146177] -1061.404049022458\n","[9.09117323 0.13041943 1.10146177] -1061.404049020924\n","[9.09117323 0.13041942 1.10146179] -1061.4040490203718\n","[9.08820427 0.13080806 1.09958718] -1061.403991877077\n","[9.08820427 0.13080806 1.09958718] -1061.403991877077\n","[9.08820429 0.13080806 1.09958718] -1061.403991877003\n","[9.08820427 0.13080807 1.09958718] -1061.4039918770625\n","[9.08820427 0.13080806 1.09958719] -1061.4039918770973\n","[9.08885104 0.13155883 1.09999873] -1061.4039904469582\n","[9.08885104 0.13155883 1.09999873] -1061.4039904469582\n","[9.08885105 0.13155883 1.09999873] -1061.4039904469396\n","[9.08885104 0.13155884 1.09999873] -1061.4039904469705\n","[9.08885104 0.13155883 1.09999875] -1061.4039904469898\n","     fun: 1061.4039904469582\n","     jac: array([-0.00125122,  0.00082397,  0.00212097])\n"," message: 'Optimization terminated successfully.'\n","    nfev: 35\n","     nit: 6\n","    njev: 6\n","  status: 0\n"," success: True\n","       x: array([9.08885104, 0.13155883, 1.09999873])\n","[(        state  action\n","0         129       0\n","1         131       0\n","2         133       0\n","3         135       0\n","4         137       0\n","...       ...     ...\n","299995    174       0\n","299996    174       0\n","299997    174       0\n","299998    174       0\n","299999    174       0\n","\n","[300000 rows x 2 columns], {'state': array([[129, 131, 133, ..., 174, 174, 174],\n","       [ 58,  59,  61, ..., 174, 174, 174],\n","       [ 49,  51,  53, ..., 174, 174, 174],\n","       ...,\n","       [ 95,  96,  98, ..., 174, 174, 174],\n","       [ 52,  53,  55, ..., 149, 150, 151],\n","       [157, 159, 160, ..., 174, 174, 174]]), 'action': array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]]), 'hidden': array([[0, 0, 0, ..., 1, 1, 1],\n","       [0, 0, 0, ..., 1, 1, 1],\n","       [0, 0, 0, ..., 1, 1, 1],\n","       ...,\n","       [0, 0, 0, ..., 1, 1, 1],\n","       [0, 0, 0, ..., 1, 1, 1],\n","       [0, 0, 0, ..., 1, 1, 1]]), 'belief': array([[0.        , 0.012     , 0.1105027 , ..., 0.0150813 , 0.0150813 ,\n","        0.0150813 ],\n","       [0.        , 0.012     , 0.1105027 , ..., 0.0150813 , 0.0150813 ,\n","        0.0150813 ],\n","       [0.        , 0.012     , 0.1105027 , ..., 0.0150813 , 0.0150813 ,\n","        0.0150813 ],\n","       ...,\n","       [1.        , 0.949     , 0.94382256, ..., 0.0150813 , 0.0150813 ,\n","        0.0150813 ],\n","       [1.        , 0.949     , 0.94382256, ..., 0.01878497, 0.01982514,\n","        0.0202633 ],\n","       [1.        , 0.949     , 0.84699123, ..., 0.0150813 , 0.0150813 ,\n","        0.0150813 ]]), 'pis': 0.9509143407122231}),      fun: 1061.4039904469582\n","     jac: array([-0.00125122,  0.00082397,  0.00212097])\n"," message: 'Optimization terminated successfully.'\n","    nfev: 35\n","     nit: 6\n","    njev: 6\n","  status: 0\n"," success: True\n","       x: array([9.08885104, 0.13155883, 1.09999873])]\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sat Nov 14 00:47:19 2020\n","11:44\n","@author: Sunlu\n","\"\"\"\n","\n","import pandas as pd\n","import numpy as np\n","import scipy.optimize as opt\n","from scipy.optimize import minimize #scipy version = 1.4.1\n","import time as tm\n","#import matplotlib.pyplot as plt\n","#import seaborn as sns\n","import pandas as pd\n","from scipy.misc import derivative\n","import warnings\n","\n","from tqdm import tqdm\n","warnings.filterwarnings(\"ignore\")\n","# warnings.filterwarnings(\"error\")\n","#\n","\n","#%%\n","# def partial_derivative(func, point):\n","#     tol = len(point)\n","#     def wraps(x,var):\n","#         args = point.copy()#[:]\n","#         args[var] = x\n","#         #print(args)\n","#         return func(args)\n","    \n","#     pd = []\n","#     for var in range(tol):\n","#         wraps_new = lambda x: wraps(x,var)\n","#         pd.append(derivative(wraps_new,point[var]))\n","        \n","#     return \n","\n","class FullLikelihood(object):\n","    def __init__(self, data, Y, X,belief0, dim_x, dim_z,time, nbus, alpha,hide_state = True, disp_status = False):\n","        \"\"\"\n","        A statistics workbench used to evaluate the cost parameters underlying \n","        a bus replacement pattern by a forward-looking agent.\n","        \n","        Input:\n","            \n","            * data: a Pandas dataframe, which contains:\n","                -Y: the name of the column containing the dummy exogenous \n","                    variable (here, the choice)\n","                -X: the name of the column containing the endogenous variable \n","                    (here, the state of the bus)\n","            \n","            * dim_x: The number of belif. Start from 0 to 1.\n","            \n","            * dim_z: The number of observation state bins.\n","            \n","            * time: The length of time horizon of the observations.           \n","            \n","            * nbus: The number of buses.\n","            \n","            * hide_state: Default is True. Decide to use Hidden model or not.\n","            \n","            * disp_status: Default is False. Print the grid of opt process.\n","        \"\"\"        \n","        self.data = np.array(data)\n","        self.alpha = alpha\n","        #self.endog = data.loc[:, Y].values\n","        self.exog = data.loc[:, X].values\n","        self.dim = dim_x     \n","        self.S = dim_z \n","        self.time = time\n","        self.nbus = nbus\n","        self.hide_state = hide_state\n","        self.disp_status = disp_status\n","        self.belief0 = belief0\n","        # To speed up computations and avoid loops when computing the log \n","        # likelihood, we create a few useful matrices here:\n","        self.N = data.loc[:, Y].values.shape[0]\n","        self.Dlength = self.S*self.dim\n","        #length = self.Dlength\n","        \n","        # A (length x 2) matrix indicating the blief of a bus at observation \n","        # state i \n","        self.D = [(i,j/(self.dim-1)) for i in range(self.S) \n","                                     for j in range(self.dim)]\n","        \n","\n","        \n","        # A (length x length) matrix indicating the probability of a bus \n","        # transitioning from a state z to a state z' with centain belif  \n","        # self.regen_mat = np.vstack((np.zeros((self.dim-1, self.Dlength)),\n","        #                             np.ones((1,self.Dlength)),\n","        #                             np.zeros((self.Dlength-self.dim, self.Dlength))))\n","        \n","        # A (2xN) matrix indicating with a dummy the decision taken by the \n","        # agent for each time/bus observation (replace or maintain)        \n","        #self.dec_mat = np.vstack(((1-data.loc[:, Y].values), data.loc[:, Y].values))\n","               \n","    def trans(self, theta2,p0,p1):\n","        \"\"\"\n","        This function generate the transition matrix\n","        \n","        Input:\n","            \n","            * theta2: The true state transition probability\n","            \n","            * p0: The transition probability when true state s = 0 (good)\n","            \n","            * p1: The transition probability when true state s = 1 (bad)\n","        Output:\n","        \n","            * trans_mat: A (length x length) matrix indicating the probability \n","                        of a bus transitioning from a obsevation state z to a \n","                        observation state z' with centain belif in good or bad\n","                        true state s.\n","        \"\"\"\n","        \n","        S = self.S\n","        D = self.D\n","        dim = self.dim\n","        length = self.Dlength\n","        \n","        p_0 = np.array([p0[0],p1[0]])\n","        p_0 = np.around(p_0,3)\n","        p_1 = np.array([p0[1],p1[1]])\n","        p_1 = np.around(p_1,3)\n","        p_2 = np.array([p0[2],p1[2]])\n","        p_2 = np.around(p_2,3)\n","        p_3 = 1-p_0-p_1-p_2\n","        \n","        #self.P = P = np.array((p_0,p_1,p_2,p_3))\n","        P = np.array((p_0,p_1,p_2,p_3))\n","        trans_mat = np.zeros((length, length))\n","        new_x0 = lambda x: np.dot(p_0*np.array([x,1-x]),theta2) / np.dot(p_0,[x,1-x])\n","        new_x1 = lambda x: np.dot(p_1*np.array([x,1-x]),theta2) / np.dot(p_1,[x,1-x])\n","        new_x2 = lambda x: np.dot(p_2*np.array([x,1-x]),theta2) / np.dot(p_2,[x,1-x])\n","        new_x3 = lambda x: np.dot(p_3*np.array([x,1-x]),theta2) / np.dot(p_3,[x,1-x])\n","        \n","        matrix0 = [new_x0(i / (dim-1)) for i in range(dim)]\n","        matrix1 = [new_x1(i / (dim-1)) for i in range(dim)]\n","        matrix2 = [new_x2(i / (dim-1)) for i in range(dim)]\n","        matrix3 = [new_x3(i / (dim-1)) for i in range(dim)]\n","        \n","        #self.matrix = x_matrix = np.vstack((matrix0,matrix1,matrix2,matrix3))\n","        x_matrix = np.vstack((matrix0,matrix1,matrix2,matrix3))\n","        \n","        for i in range(length):\n","            \n","            z_cur = D[i][0]\n","            x_cur = D[i][1]\n","            \n","            for j in range(4):\n","                \n","                if self.hide_state == True:\n","                    x_new = x_matrix[j][int(x_cur*(dim-1))]\n","                else:\n","                    x_new = 1\n","                    \n","                x_f = np.floor((self.dim-1)*x_new)/(self.dim-1)\n","                coe = (x_new-x_f)*(self.dim - 1)\n","                \n","                if z_cur + j < S-1:\n","                    ind = D.index((z_cur + j,x_f))\n","                    trans_mat[ind][i] = (1-coe)*np.dot(P[j],[x_cur,1-x_cur])\n","                    \n","                    if x_f != 1:\n","                        trans_mat[ind+1][i] = coe*np.dot(P[j],[x_cur,1-x_cur])\n","                        \n","                elif z_cur + j >= S-1:\n","                    ind = D.index((S-1,x_f))\n","                    trans_mat[ind][i] += (1-coe)*np.dot(P[j],[x_cur,1-x_cur])\n","                    \n","                    if x_f != 1:\n","                        trans_mat[ind+1][i] += coe*np.dot(P[j],[x_cur,1-x_cur])\n","                        \n","                else:\n","                    pass\n","                \n","        return trans_mat\n","    \n","    def belief(self,theta2,p0,p1, path ,x,data_gene_status = False):\n","        \"\"\"\n","        This function return the belief x\n","        \n","        Input:\n","            \n","            * theta2: The true state transition probability\n","            \n","            * p0: The transition probability when s = 0\n","            \n","            * p1: The transition probability when s = 1\n","            \n","            * path: A path of mileage and replacement/maintenance record data\n","        \n","        Output:\n","            \n","            * x: A list with length 'time'. Record belief of each state z\n","        \"\"\"\n","        if data_gene_status:\n","            #path = [[zold,action],[znew,0]]\n","            length = 2\n","            #x = [path[0][2]] #return(xold,xnew)           \n","        \n","        else:\n","            length = self.time\n","            #x = [1]\n","        x = [x]\n","        \n","        p_0 = np.array([p0[0],p1[0]])\n","        p_1 = np.array([p0[1],p1[1]])\n","        p_2 = np.array([p0[2],p1[2]])\n","        p_3 = 1-p_0-p_1-p_2\n","        \n","        for i in range(length-1):\n","            \n","            if path[i][1] == 1:\n","                x_new = 1\n","                x.append(x_new)\n","                \n","            else:\n","                x_cur= np.array([x[-1],1-x[-1]])\n","                gap = path[i+1][0]-path[i][0]\n","                \n","                if gap == 0:\n","                    v1 = np.dot(p_0,x_cur)\n","                    v2 = np.dot(p_0,np.diag(x_cur))\n","                    v3 = np.dot(v2,theta2)\n","                    try:                    \n","                        x_new = v3/v1\n","                    except RuntimeWarning:\n","                        x_new = v3/(v1+np.finfo(float).eps)\n","                    x.append(x_new)\n","                    \n","                elif gap == 1:\n","                    v1 = np.dot(p_1,x_cur)\n","                    v2 = np.dot(p_1,np.diag(x_cur))\n","                    v3 = np.dot(v2,theta2)\n","                    try:                    \n","                        x_new = v3/v1\n","                    except RuntimeWarning:\n","                        x_new = v3/(v1+np.finfo(float).eps)\n","                    x.append(x_new)\n","                    \n","                elif gap == 2:\n","                    v1 = np.dot(p_2,x_cur)\n","                    v2 = np.dot(p_2,np.diag(x_cur))\n","                    v3 = np.dot(v2,theta2)\n","                    try:                    \n","                        x_new = v3/v1\n","                    except RuntimeWarning:\n","                        x_new = v3/(v1+np.finfo(float).eps)\n","                    x.append(x_new)\n","                    \n","                else:\n","                    v1 = np.dot(p_3,x_cur)\n","                    v2 = np.dot(p_3,np.diag(x_cur))\n","                    v3 = np.dot(v2,theta2)\n","                    try:                    \n","                        x_new = v3/v1\n","                    except RuntimeWarning:\n","                        x_new = v3/(v1+np.finfo(float).eps)\n","                    x.append(x_new)\n","        return x\n","    \n","    def simulation(self, dim_x0,SampleSize, TimePeriod, reward = [9.243,0.226,1.164],theta2 = [0.949,0.012],\\\n","                    p0 = [0.039,0.333,0.590],p1=[0.181,0.757,0.061],rand_status = False):\n","        reward = [rw*self.alpha for rw in reward]\n","        print(reward)\n","        condition = np.zeros([SampleSize,TimePeriod],dtype = int) #hidden state: 0,1\n","        state = np.zeros([SampleSize,TimePeriod],dtype = int ) #mileage: 175:0,...,174\n","        x = np.ones([SampleSize,TimePeriod])#belief: s = 0 prob # 删除\n","        if rand_status: # s0 z0 x0\n","            x[:,0] = np.kron(np.linspace(0, 1,num= dim_x0),np.ones(int(SampleSize/dim_x0)))\n","        \n","            #x[:,0] = np.kron(np.random.uniform(size = dim_x0),np.ones(int(SampleSize/dim_x0)))\n","            state[:,0] = np.random.choice(np.arange(175,dtype= int),size = SampleSize,p=np.ones(175)/175)#uniform(0,20)\n","            pis =0.9509143407122231#np.random.uniform()#0.5#\n","            condition[:,0] = np.random.choice([0,1],size = SampleSize, p = [pis,1-pis])#0000\n","        else:\n","            pis = 1\n","        action = np.zeros([SampleSize,TimePeriod],dtype = int)\n","        rho = 1\n","        print(\"generate Q\")\n","        Q = self.fl_costs( reward, theta2, p0, p1 ) # Q function Q(x,a) --> interpolation \n","        pchoice =self.choice_prob(rho,Q) # z = 0, x= 0, 0.1, 0.2,....,1, z = 1, x = 0,...,1 pi\n","        print(\"generate dataset\")\n","        for nbus in tqdm(range(SampleSize)):\n","            for t in range(TimePeriod-1):\n","                path = np.zeros([2,2])\n","                path[0,0] = state[nbus,t]\n","                #path[0,2] = x[nbus,t] \n","                \n","                fl =  int(np.floor(x[nbus,t]*(self.dim-1)))\n","                cl =  int(np.ceil(x[nbus,t]*(self.dim-1)))\n","                coef = x[nbus,t] * (self.dim-1)-fl\n","                pi0 = pchoice[state[nbus,t] * self.dim + fl,0] * (1-coef) +\\\n","                    pchoice[state[nbus,t] * self.dim + cl,0] *coef\n","                    \n","                action[nbus,t] = np.random.choice([0,1],p=[pi0,1-pi0])\n","                path[0,1] = action[nbus,t]\n","                \n","                if action[nbus,t]==1:\n","                    state[nbus,t+1] = 0\n","                    condition[nbus,t+1] = 0\n","                    path[1,0] = state[nbus,t+1]\n","                else:\n","                    if condition[nbus,t] == 0:\n","                        state[nbus,t+1] = state[nbus,t] + np.random.choice([0,1,2,3],p=[p0[0],p0[1],p0[2],1-np.sum(p0)])\n","                        if state[nbus,t+1]>self.S-1:\n","                            state[nbus,t+1] = self.S-1\n","                            \n","                        condition[nbus,t+1] = np.random.choice([0,1],p=[theta2[0],1-theta2[0]])\n","                        path[1,0] = state[nbus,t+1]  \n","                    else:\n","                        state[nbus,t+1] = state[nbus,t] + np.random.choice([0,1,2,3],p=[p1[0],p1[1],p1[2],1-np.sum(p1)])\n","                        if state[nbus,t+1]>self.S-1:\n","                            state[nbus,t+1] = self.S-1\n","                        condition[nbus,t+1] = np.random.choice([0,1],p=[theta2[1],1-theta2[1]])\n","                        path[1,0] = state[nbus,t+1]\n","                x[nbus,t+1] = self.belief(theta2,p0,p1, path,x[nbus,t] ,data_gene_status = True)[-1]\n","                \n","            fl =  int(np.floor(x[nbus,TimePeriod-1]*(self.dim-1)))\n","            cl =  int(np.ceil(x[nbus,TimePeriod-1]*(self.dim-1)))\n","            coef = x[nbus,TimePeriod-1] * (self.dim-1)-fl\n","            pi0 = pchoice[state[nbus,TimePeriod-1] * self.dim + fl,0] * (1-coef) +\\\n","                pchoice[state[nbus,TimePeriod-1] * self.dim + cl,0] *coef\n","                \n","            action[nbus,TimePeriod-1] = np.random.choice([0,1],p=[pi0,1-pi0])        \n","          \n","        state_new = np.reshape(state,[-1])\n","        action_new = np.reshape(action,[-1])\n","        data = {'state':state_new,'action':action_new}\n","        dat_new = pd.DataFrame(data=data)\n","        \n","        return dat_new,{'state':state,'action':action,'hidden':condition,'belief':x,'pis':pis}\n","    \n","    def myopic_costs(self, params):\n","        \"\"\"\n","        This function computes the myopic expected cost associated with each \n","        decision for each state.\n","\n","        Input:\n","\n","            * params: A vector, to be supplied to the maintenance linear cost \n","            function. The first element of the vector is the replacement cost rc.\n","\n","        Output:\n","            \n","            * A (length x 2) array containing the maintenance and replacement \n","            costs for the z possible states of the bus.\n","        \"\"\"\n","        \n","        length = self.Dlength\n","        D = self.D\n","        rc = params[0]\n","        thetas = np.array(params[1:])\n","        maint_cost = np.array([np.dot(0.001*D[d][0]*thetas,[D[d][1],1-D[d][1]])\n","                               for d in range(0, length)])\n","        repl_cost = [rc for d in range(0, length)]\n","\n","        return  np.vstack((maint_cost, repl_cost)).T\n","     \n","    def fl_costs(self, params, theta2, p0, p1 ,beta=0.9, threading = 1e-3):#beta=0.9999, threading = 3e-3):#beta=0.9999, threading = 0.45):#\n","        \"\"\"\n","        Compute the non-myopic expected value of the agent for each possible \n","        decision and each possible state of the bus, conditional on a vector of \n","        parameters and on the maintenance cost function specified at the \n","        initialization of the DynamicUtility model.\n","\n","        Iterates until the difference in the previously obtained expected value \n","        and the new expected value is smaller than a constant 'threading'.\n","\n","        Input:\n","\n","            * params: A vector params for the cost function\n","\n","            * theta2: Hiden state transition probability\n","\n","            * p0: The transition probability when s = 0\n","\n","            * p1: The transition probability when s = 1\n","\n","            * beta: Default is 0.9999. A discount factor beta (optional)\n","\n","            * threading: Default is 0.45. A convergence threshold (optional)\n","\n","        Output:\n","\n","            * EV_new: A (length x 2) array of forward-looking costs associated \n","                    with each state z and each belief. Definded as Q\n","        \"\"\"\n","\n","        # Initialization of the contraction mapping\n","        #self.EV_myopic =self.myopic_costs(params)\n","        params = np.array(params)/self.alpha\n","        EV_myopic =self.myopic_costs(params)\n","        \n","        EV_new = EV_myopic\n","\n","        EV = np.zeros(EV_new.shape)        \n","        #VError = np.max(abs(EV-EV_new))\n","        VError = np.max(abs(EV-EV_new))/np.max(np.abs(EV))\n","\n","        #print('Initial Error:',VError,np.max(abs(EV_new)))\n","\n","        #self.trans_mat = self.trans(theta2,p0,p1)\n","        trans_mat = self.trans(theta2,p0,p1)\n","        # Contraction mapping Loop\n","        i = 0\n","        length = self.Dlength\n","        \n","        while(VError>threading):         \n","\n","            EV = EV_new\n","            m = EV.min(1).reshape(length, -1)\n","            #ecost = np.log(np.exp(-EV+m).sum(1) )-m.T+0.5772\n","            ecost = np.log(np.exp(-EV+m).sum(1) )-m.T+0.5772\n","          \n","            futil_maint = np.dot(ecost, trans_mat)\n","            futil_repl = np.dot(ecost, np.vstack((np.zeros((self.dim-1, self.Dlength)),\n","                                    np.ones((1,self.Dlength)),\n","                                    np.zeros((self.Dlength-self.dim, self.Dlength)))))\n","            futil = np.vstack((futil_maint, futil_repl)).T\n","            EV_new = EV_myopic - beta * futil\n","\n","            i +=1\n","            # VError = np.max(abs(EV-EV_new))\n","            # print(i,'th Error:',VError,VError/np.max(abs(EV)),np.max(abs(EV_new)))\n","\n","            VError = np.max(abs(EV-EV_new))/np.max(np.abs(EV))\n","            #print(i,'th Error:',VError,np.max(abs(EV-EV_new)),np.max(abs(EV_new)))\n","\n","            if i>1000:\n","                break\n","            \n","        #print('{}, Eorror:'.format(i),VError,np.max(abs(EV_new)))   \n","\n","        return EV_new\n","\n","    def choice_prob(self, rho, cost_array):\n","        \"\"\"\n","        Returns the probability of each choice for each observed state, \n","        conditional on an array of state/decision costs (generated by the \n","        myopic or forward-looking cost functions)\n","        \"\"\"\n","        cost_array = cost_array/rho\n","        cost = cost_array - cost_array.min(1).reshape(self.Dlength, -1)\n","        #util = np.exp(-cost)\n","        util = np.exp(-cost)\n","        pchoice = util / (np.sum(util, 1).reshape(self.Dlength, -1))\n","\n","        return pchoice\n","\n","    # def loglike_full(self,theta2):\n","    #     \"\"\"\n","    #     The log-likelihood of the Dynamic model(theta 2) is estimated.\n","    #     \"\"\"\n","    #     self.theta2 = theta2\n","    #     self.fit_likelihood2()\n","        \n","    #     loglike = -self.fitted2.fun\n","        \n","    #     if self.disp_status:\n","    #         print(theta2,loglike)\n","\n","    #     return -loglike\n","   \n","    def loglike2(self,parameters):\n","        if len(parameters)==8:\n","            theta2 = parameters[6:8]\n","        else:\n","            theta2 = self.theta2\n","        \n","    # def loglike2(self,parameters):\n","    #     \"\"\"\n","    #     The log-likelihood of the Dynamic model(theta 3) is estimated.\n","    #     \"\"\"\n","\n","    #     theta2 = parameters[6:]\n","        p0 = parameters[0:3]\n","        p1 = parameters[3:6]\n","        \n","        prob0 = np.array([p0[0],p1[0]])\n","        prob1 = np.array([p0[1],p1[1]])\n","        prob2 = np.array([p0[2],p1[2]])\n","\n","        prob3 = 1 - prob0 -prob1 - prob2\n","\n","        mileage = self.exog\n","\n","        if self.hide_state == True:\n","            beli = []\n","            \n","            for i in range(self.nbus):\n","                beli = beli + self.belief(theta2,p0,p1,\n","                                self.data[i*self.time:(i+1)*self.time],self.belief0[i])\n","        else:\n","            beli = [1 for s in range(0,self.N)]\n","        \n","        logprob = 0\n","        for i in range(self.N-1):\n","            x_cur = [beli[i], 1-beli[i]]\n","\n","            if mileage[i+1] - mileage[i] == 0:\n","                try:\n","                    logprob += np.log(np.dot(prob0,x_cur))\n","                except RuntimeWarning:\n","                    logprob += np.log(np.finfo(float).eps)\n","            \n","            elif mileage[i+1] - mileage[i] == 1:\n","                try:\n","                    logprob += np.log(np.dot(prob1,x_cur))\n","                except RuntimeWarning:\n","                    logprob += np.log(np.finfo(float).eps)             \n","\n","            elif mileage[i+1] - mileage[i] == 2:\n","                try:\n","                    logprob += np.log(np.dot(prob2,x_cur))\n","                except RuntimeWarning:\n","                    logprob += np.log(np.finfo(float).eps)\n","\n","            elif mileage[i+1] - mileage[i] == 3:\n","                try:\n","                    logprob += np.log(np.dot(prob3,x_cur))\n","                except RuntimeWarning:\n","                    logprob += np.log(np.finfo(float).eps)\n","\n","        #print(f'current likelihood: {logprob}')\n","\n","        if self.disp_status:\n","            print(parameters,logprob)\n","        return -logprob/self.time/self.nbus\n","\n","    def loglike(self, parameters, p0, p1, theta2):\n","        \"\"\"\n","        The log-likelihood of the reward model is estimated in several steps.\n","\n","        1°) The current parameters are supplied to the contraction mapping \n","            function\n","\n","        2°) The function returns a matrix of decision probabilities for each \n","            state.\n","\n","        3°) This matrix is used to compute the loglikelihood of the \n","            observations\n","\n","        4°) The log-likelihood are then summed accross individuals, and \n","            returned\n","        \"\"\"\n","\n","        params = parameters[0:3]\n","        rho = 1\n","\n","        # p0 = self.fitted2.x[0:3]\n","        # p1 = self.fitted2.x[3:6]\n","        # theta2 = self.theta2\n","        # A (length x 1) matrix        \n","         \n","\n","        beli = []\n","        #self.beli = []\n","\n","        for i in range(self.nbus):\n","            beli = beli + self.belief(theta2,p0,p1,\n","                                        self.data[i*self.time:(i+1)*self.time],self.belief0[i])\n","\n","\n","        # bool_to_int_f = np.array(((np.array((np.ones((self.Dlength,1)) * self.exog.reshape((1,self.N))) == (np.array(self.D).T[0].reshape((self.Dlength,1)) * np.ones((1,self.N))), dtype=int)) + \\\n","        #                           np.array((np.ones((self.Dlength,1)) * np.floor((np.array(self.beli).reshape((1,self.N)))*(self.dim-1)) / (self.dim-1)) == (np.array(self.D).T[1].reshape((self.Dlength,1)) * np.ones((1,self.N))), dtype=int)) == 2, dtype=int)\n","        # bool_to_int_c = np.array(((np.array((np.ones((self.Dlength,1)) * self.exog.reshape((1,self.N))) == (np.array(self.D).T[0].reshape((self.Dlength,1)) * np.ones((1,self.N))), dtype=int)) +\\\n","        #                           np.array((np.ones((self.Dlength,1)) * np.ceil((np.array(self.beli).reshape((1,self.N))) * (self.dim-1)) / (self.dim-1)) == (np.array(self.D).T[1].reshape((self.Dlength,1)) * np.ones((1,self.N))), dtype=int)) == 2, dtype=int)\n","\n","        # #self.state_mat =\n","        \n","        # self.D = [(i,j/(self.dim-1)) for i in range(self.S) \n","        #                              for j in range(self.dim)]\n","        bool_floor = np.int_(np.floor(np.array(beli)*(self.dim-1)))\n","        bool_ceil = np.int_(np.ceil(np.array(beli)*(self.dim-1)))\n","        bool_non0 = np.where((bool_floor-bool_ceil)!=0)\n","        coef_floor = np.zeros(bool_floor.shape)\n","        coef_floor[bool_non0] = (np.array(beli)*(self.dim-1)-bool_ceil)[bool_non0]/(bool_floor-bool_ceil)[bool_non0]\n","        \n","        choiceProb = self.choice_prob(rho,self.fl_costs(params,theta2,p0,p1)) #states,actions\n","        action = np.int_(self.data[:,1])\n","        statef =  np.int_(self.exog*self.dim+bool_floor)\n","        statec = np.int_(self.exog*self.dim+bool_ceil)\n","        logprob = coef_floor * choiceProb[statef,action] + (1-coef_floor)* choiceProb[statec,action] \n","        \n","        logprob = np.sum(np.log(logprob))\n","        \n","        if self.disp_status:\n","            print(parameters,logprob)\n","\n","        #print(f'current likelihood:{parameters} {logprob}')\n","\n","        return -logprob#/self.time/self.nbus\n","    \n","    \n","    \n","    def fit_likelihood2(self):\n","        \"\"\"\n","        estimate the dynamic(theta 3)\n","        \"\"\"\n","        # bounds = [(0.001, 0.998),(0.001, 0.998),(0.001, 0.998),\n","        #           (0.001, 0.998),(0.001, 0.998),(0.001, 0.998),\n","        #           (0,0.99999),(0,0.99999)]\n","        #x0 = [0.1,0.1,0.1,0.1,0.1,0.1, 0.1, 0.1]\n","        x0 = np.array([0.039,0.333,0.590,0.181,0.757,0.061,0.949,0.012])\n","        cons= ({'type': 'ineq', 'fun': lambda x: x[0]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[1]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[2]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[3]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[4]-0.001},\\\n","                {'type': 'ineq', 'fun': lambda x: x[5]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[6]},\\\n","                {'type': 'ineq', 'fun': lambda x: x[7]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[0]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[1]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[2]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[3]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[4]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[5]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.99999-x[6]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.99999-x[7]},\\\n","                {'type': 'ineq', 'fun': lambda x: 1-x[0]-x[1]-x[2]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: 1-x[3]-x[4]-x[5]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: -3*x[0]-2*x[1]-x[2]+3*x[3]+2*x[4]+x[5] })\n","        # x0 = [0.1,0.1,0.1,0.1,0.1,0.1]\n","        # cons= ({'type': 'ineq', 'fun': lambda x: x[0]-0.001 },\\\n","        #        {'type': 'ineq', 'fun': lambda x: x[1]-0.001 },\\\n","        #        {'type': 'ineq', 'fun': lambda x: x[2]-0.001 },\\\n","        #        {'type': 'ineq', 'fun': lambda x: x[3]-0.001 },\\\n","        #        {'type': 'ineq', 'fun': lambda x: x[4]-0.001},\\\n","        #        {'type': 'ineq', 'fun': lambda x: x[5]-0.001 },\\\n","        #        {'type': 'ineq', 'fun': lambda x: 0.998-x[0]},\\\n","        #        {'type': 'ineq', 'fun': lambda x: 0.998-x[1]},\\\n","        #        {'type': 'ineq', 'fun': lambda x: 0.998-x[2]},\\\n","        #        {'type': 'ineq', 'fun': lambda x: 0.998-x[3]},\\\n","        #        {'type': 'ineq', 'fun': lambda x: 0.998-x[4]},\\\n","        #        {'type': 'ineq', 'fun': lambda x: 0.998-x[5]},\\\n","        #        {'type': 'ineq', 'fun': lambda x: 1-x[0]-x[1]-x[2]-0.001 },\\\n","        #        {'type': 'ineq', 'fun': lambda x: 1-x[3]-x[4]-x[5]-0.001 },\\\n","        #        {'type': 'ineq', 'fun': lambda x: -3*x[0]-2*x[1]-x[2]+3*x[3]+2*x[4]+x[5] })\n","        self.fitted2 = minimize(\n","            self.loglike2,\n","            x0=x0,#bounds = bounds,\n","            constraints= cons,\n","            options={'disp': True})\n","        if len(x0)==8:\n","            self.theta2 = self.fitted2.x[6:8]\n","        \n","    def fit_likelihood(self, x0=None, bounds=None,p0 =None,p1=None ):\n","        \"\"\"\n","        estimate the reward parameter\n","        \"\"\"\n","        if bounds == None:\n","            bounds = [(1e-6, 100),(1e-6,100),(1e-6,100)]\n","\n","        if x0 == None:\n","            #x0 = [10,1,1,]\n","            #x0 =  [9.36, 0.94, 0.94] # To speed up, choose a closer initial point\n","            #x0 = [0.1, 0.1, 0.1]\n","            x0 = np.array([9.243,0.226,1.164])*self.alpha#[9,0.5,1]\n","        if np.sum(p0==None) and np.sum(p1==None):\n","            p0 = self.fitted2.x[0:3]\n","            p1 = self.fitted2.x[3:6]\n","        theta2 = self.theta2\n","        #theta2 = self.fitted2.x[6:8]\n","        #p0 = [0.03920017, 0.33350266, 0.59020078]\n","        #p1 = [0.18078681, 0.75749297, 0.06072025]\n","        #theta2 = [0.94946915, 0.01199934]\n","        cons= ({'type': 'ineq', 'fun': lambda x: x[2]-x[1] },\\\n","                {'type': 'ineq', 'fun': lambda x: x[0]-1e-6 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[1]-1e-6 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[2]-1e-6 },\\\n","                {'type': 'ineq', 'fun': lambda x: 100-x[0]},\\\n","                {'type': 'ineq', 'fun': lambda x: 100-x[1]},\\\n","                {'type': 'ineq', 'fun': lambda x: 100-x[2]})\n","        self.fitted = minimize(\n","            self.loglike, x0=x0,#bounds = bounds, \n","            constraints= cons, args=(p0, p1, theta2))\n","        \n","        # bounds = [(1e-6,15),(1e-6 ,2),(1e-6 ,2)]\n","        # func = lambda parameters: self. loglike(parameters, p0, p1, theta2)\n","        # self.fitted = opt.brute(func, bounds, Ns = 3) # To speed up, Ns=3\n","        \n","\n","\n","\n","#%%\n","import pickle\n","import os\n","if __name__ == \"__main__\":\n","    \n","    print('Reminder1: file group4_new_175.csv should be in the same file directory')\n","    print('Reminder2: the code will take almost 4 hours')\n","    \n","    # a dataframe has two columns, named \"state\" and \"action\".    \n","    \n","    nbus = 3000\n","    time = 100\n","    dim_x = 100\n","    \n","    print('->Date generation')\n","    filename = '/content/drive/MyDrive/2022_SUMMER/Research_Rust_Hidden/Code/'\n","    \n","    dat3 = pd.read_csv(filename+'group4_new_175.csv') \n","    estimation1 = FullLikelihood(dat3,'action','state', np.ones(37),\n","                            dim_x =51,dim_z = 175,time = 117, nbus = 37, alpha =0.001,\n","                            hide_state = True, disp_status = False)\n","    res = estimation1.simulation(dim_x,nbus,time,rand_status = True)\n","    \n","    data_record = [] \n","    data_record.append(res)\n","    \n","    # with open('data/sample1500.txt', \"rb\") as fp:   #Pickling\n","    #     res = pickle.load(fp)    \n","        \n","    # # datagenerate1 = FullLikelihood(res['res'][0],'action','state', res['res'][1]['belief'][:,0],\n","    # #                         dim_x =51,dim_z = 175,time = time, nbus = nbus, \n","    # #                         hide_state = True, disp_status = False)\n","    # # res_add = datagenerate1.simulation(15,nbus,time,rand_status = True)\n","    # # datagenerate1.theta2 = [0.949,0.012]\n","    # # loglike1 = datagenerate1.loglike2(parameters=[0.039,0.333,0.590,0.181,0.757,0.061])\n","    # # loglike2 = datagenerate1.loglike(parameters=[9.243,0.226,1.164],\\\n","    # #                 p0 = [0.039,0.333,0.590],p1=[0.181,0.757,0.061],theta2 = [0.949,0.012])\n","    # # print('true loglike1:' ,loglike1)\n","    # # print('true loglike2', loglike2)\n","    # data_record.append([0.949,0.012])\n","    # # data_record.append(loglike1)\n","    # data_record.append([0.039,0.333,0.590,0.181,0.757,0.061])\n","    # # data_record.append(loglike2)\n","    # data_record.append([9.243,0.226,1.164])\n","    \n","\n","    #     #Record in form: \n","    # #       theta2, logSigma, theta3, success1, ccp, [Rc,r1,r2], success2\n","    \n","    alpha_full = np.array([1])\n","    for alpha in alpha_full:\n","        print('->Estimation1 x0 known, alpha = ', alpha)\n","        timeStart = tm.time()\n","        \n","        #Initialize\n","        estimation1 = FullLikelihood(res[0].head(nbus*time),'action','state', res[1]['belief'][0:nbus*time,0],\n","                                dim_x =51,dim_z = 175,time = time, nbus = nbus, alpha =alpha,\n","                                hide_state = True, disp_status = True)\n","        # estimation1.fit_likelihood2()\n","        # data_record.append(estimation1.fitted2)\n","        # print(estimation1.fitted2)\n","        estimation1.theta2 = [0.949,0.012]\n","        estimation1.fit_likelihood(p0 = [0.039,0.333,0.590],p1=[0.181,0.757,0.061])\n","        # estimation1.fit_likelihood()\n","        data_record.append(estimation1.fitted)\n","        print(estimation1.fitted)\n","    \n","    print(data_record)\n","    with open(filename+'samplefinal1_'+str(dim_x)+'_'+str(nbus)+'_'+str(time)+'.txt', \"wb\") as fp:   #Pickling\n","        res = pickle.dump(data_record,fp)   \n","                    "]}]}