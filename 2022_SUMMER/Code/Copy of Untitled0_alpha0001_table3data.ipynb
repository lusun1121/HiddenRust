{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":819,"status":"ok","timestamp":1656342034126,"user":{"displayName":"Lu Sun","userId":"12220989488268625125"},"user_tz":300},"id":"tTM-UtbdzHc8","outputId":"5cfe130a-e1b6-4a08-9d8f-237f9d39066c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6461,"status":"ok","timestamp":1656342040583,"user":{"displayName":"Lu Sun","userId":"12220989488268625125"},"user_tz":300},"id":"6XaNc3CzypXo"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sat Nov 14 00:47:19 2020\n","11:44\n","@author: Sunlu\n","\"\"\"\n","\n","import pandas as pd\n","import numpy as np\n","import scipy.optimize as opt\n","from scipy.optimize import minimize #scipy version = 1.4.1\n","import time as tm\n","#import matplotlib.pyplot as plt\n","#import seaborn as sns\n","import pandas as pd\n","from scipy.misc import derivative\n","import warnings\n","\n","from tqdm import tqdm\n","warnings.filterwarnings(\"ignore\")\n","# warnings.filterwarnings(\"error\")\n","#\n","\n","\n","class FullLikelihood(object):\n","    def __init__(self, data, Y, X,belief0, dim_x, dim_z,time, nbus, alpha,hide_state = True, disp_status = False):\n","\n","        self.data = np.array(data)\n","        self.alpha = alpha\n","        #self.endog = data.loc[:, Y].values\n","        self.exog = data.loc[:, X].values\n","        self.dim = dim_x     \n","        self.S = dim_z \n","        self.time = time\n","        self.nbus = nbus\n","        self.hide_state = hide_state\n","        self.disp_status = disp_status\n","        self.belief0 = belief0\n","        # To speed up computations and avoid loops when computing the log \n","        # likelihood, we create a few useful matrices here:\n","        self.N = data.loc[:, Y].values.shape[0]\n","        self.Dlength = self.S*self.dim\n","        #length = self.Dlength\n","        \n","        # A (length x 2) matrix indicating the blief of a bus at observation \n","        # state i \n","        self.D = [(i,j/(self.dim-1)) for i in range(self.S) \n","                                     for j in range(self.dim)]\n","               \n","    def trans(self, theta2,p0,p1):\n","        \n","        S = self.S\n","        D = self.D\n","        dim = self.dim\n","        length = self.Dlength\n","        \n","        p_0 = np.array([p0[0],p1[0]])\n","        p_0 = np.around(p_0,3)\n","        p_1 = np.array([p0[1],p1[1]])\n","        p_1 = np.around(p_1,3)\n","        p_2 = np.array([p0[2],p1[2]])\n","        p_2 = np.around(p_2,3)\n","        p_3 = 1-p_0-p_1-p_2\n","        \n","        #self.P = P = np.array((p_0,p_1,p_2,p_3))\n","        P = np.array((p_0,p_1,p_2,p_3))\n","        trans_mat = np.zeros((length, length))\n","        new_x0 = lambda x: np.dot(p_0*np.array([x,1-x]),theta2) / np.dot(p_0,[x,1-x])\n","        new_x1 = lambda x: np.dot(p_1*np.array([x,1-x]),theta2) / np.dot(p_1,[x,1-x])\n","        new_x2 = lambda x: np.dot(p_2*np.array([x,1-x]),theta2) / np.dot(p_2,[x,1-x])\n","        new_x3 = lambda x: np.dot(p_3*np.array([x,1-x]),theta2) / np.dot(p_3,[x,1-x])\n","        \n","        matrix0 = [new_x0(i / (dim-1)) for i in range(dim)]\n","        matrix1 = [new_x1(i / (dim-1)) for i in range(dim)]\n","        matrix2 = [new_x2(i / (dim-1)) for i in range(dim)]\n","        matrix3 = [new_x3(i / (dim-1)) for i in range(dim)]\n","        \n","        #self.matrix = x_matrix = np.vstack((matrix0,matrix1,matrix2,matrix3))\n","        x_matrix = np.vstack((matrix0,matrix1,matrix2,matrix3))\n","        \n","        for i in range(length):\n","            \n","            z_cur = D[i][0]\n","            x_cur = D[i][1]\n","            \n","            for j in range(4):\n","                \n","                if self.hide_state == True:\n","                    x_new = x_matrix[j][int(x_cur*(dim-1))]\n","                else:\n","                    x_new = 1\n","                    \n","                x_f = np.floor((self.dim-1)*x_new)/(self.dim-1)\n","                coe = (x_new-x_f)*(self.dim - 1)\n","                \n","                if z_cur + j \u003c S-1:\n","                    ind = D.index((z_cur + j,x_f))\n","                    trans_mat[ind][i] = (1-coe)*np.dot(P[j],[x_cur,1-x_cur])\n","                    \n","                    if x_f != 1:\n","                        trans_mat[ind+1][i] = coe*np.dot(P[j],[x_cur,1-x_cur])\n","                        \n","                elif z_cur + j \u003e= S-1:\n","                    ind = D.index((S-1,x_f))\n","                    trans_mat[ind][i] += (1-coe)*np.dot(P[j],[x_cur,1-x_cur])\n","                    \n","                    if x_f != 1:\n","                        trans_mat[ind+1][i] += coe*np.dot(P[j],[x_cur,1-x_cur])\n","                        \n","                else:\n","                    pass\n","                \n","        return trans_mat\n","    \n","    def belief(self,theta2,p0,p1, path ,x,data_gene_status = False):\n","\n","        if data_gene_status:\n","            #path = [[zold,action],[znew,0]]\n","            length = 2\n","            #x = [path[0][2]] #return(xold,xnew)           \n","        \n","        else:\n","            length = self.time\n","            #x = [1]\n","        x = [x]\n","        \n","        p_0 = np.array([p0[0],p1[0]])\n","        p_1 = np.array([p0[1],p1[1]])\n","        p_2 = np.array([p0[2],p1[2]])\n","        p_3 = 1-p_0-p_1-p_2\n","        \n","        for i in range(length-1):\n","            \n","            if path[i][1] == 1:\n","                x_new = 1\n","                x.append(x_new)\n","                \n","            else:\n","                x_cur= np.array([x[-1],1-x[-1]])\n","                gap = path[i+1][0]-path[i][0]\n","                \n","                if gap == 0:\n","                    v1 = np.dot(p_0,x_cur)\n","                    v2 = np.dot(p_0,np.diag(x_cur))\n","                    v3 = np.dot(v2,theta2)\n","                    try:                    \n","                        x_new = v3/v1\n","                    except RuntimeWarning:\n","                        x_new = v3/(v1+np.finfo(float).eps)\n","                    x.append(x_new)\n","                    \n","                elif gap == 1:\n","                    v1 = np.dot(p_1,x_cur)\n","                    v2 = np.dot(p_1,np.diag(x_cur))\n","                    v3 = np.dot(v2,theta2)\n","                    try:                    \n","                        x_new = v3/v1\n","                    except RuntimeWarning:\n","                        x_new = v3/(v1+np.finfo(float).eps)\n","                    x.append(x_new)\n","                    \n","                elif gap == 2:\n","                    v1 = np.dot(p_2,x_cur)\n","                    v2 = np.dot(p_2,np.diag(x_cur))\n","                    v3 = np.dot(v2,theta2)\n","                    try:                    \n","                        x_new = v3/v1\n","                    except RuntimeWarning:\n","                        x_new = v3/(v1+np.finfo(float).eps)\n","                    x.append(x_new)\n","                    \n","                else:\n","                    v1 = np.dot(p_3,x_cur)\n","                    v2 = np.dot(p_3,np.diag(x_cur))\n","                    v3 = np.dot(v2,theta2)\n","                    try:                    \n","                        x_new = v3/v1\n","                    except RuntimeWarning:\n","                        x_new = v3/(v1+np.finfo(float).eps)\n","                    x.append(x_new)\n","        return x\n","    \n","    def simulation(self, dim_x0,SampleSize, TimePeriod, reward = [9.243,0.226,1.164],theta2 = [0.949,0.012],\\\n","                    p0 = [0.039,0.333,0.590],p1=[0.181,0.757,0.061],rand_status = False):\n","        reward = [rw*self.alpha for rw in reward]\n","        print(reward)\n","        condition = np.zeros([SampleSize,TimePeriod],dtype = int) #hidden state: 0,1\n","        state = np.zeros([SampleSize,TimePeriod],dtype = int ) #mileage: 175:0,...,174\n","        x = np.ones([SampleSize,TimePeriod])#belief: s = 0 prob # 删除\n","        if rand_status: # s0 z0 x0\n","            x[:,0] = np.kron(np.linspace(0, 1,num= dim_x0),np.ones(int(SampleSize/dim_x0)))\n","        \n","            #x[:,0] = np.kron(np.random.uniform(size = dim_x0),np.ones(int(SampleSize/dim_x0)))\n","            state[:,0] = np.random.choice(np.arange(110,dtype= int),size = SampleSize,p=np.ones(110)/110)#uniform(0,20)\n","            pis =0.9509143407122231#np.random.uniform()#0.5#\n","            condition[:,0] = np.random.choice([0,1],size = SampleSize, p = [pis,1-pis])#0000\n","        else:\n","            pis = 1\n","        action = np.zeros([SampleSize,TimePeriod],dtype = int)\n","        rho = 1\n","        print(\"generate Q\")\n","        Q = self.fl_costs( reward, theta2, p0, p1 ) # Q function Q(x,a) --\u003e interpolation \n","        pchoice =self.choice_prob(rho,Q) # z = 0, x= 0, 0.1, 0.2,....,1, z = 1, x = 0,...,1 pi\n","        print(\"generate dataset\")\n","        for nbus in tqdm(range(SampleSize)):\n","            for t in range(TimePeriod-1):\n","                path = np.zeros([2,2])\n","                path[0,0] = state[nbus,t]\n","                #path[0,2] = x[nbus,t] \n","                \n","                fl =  int(np.floor(x[nbus,t]*(self.dim-1)))\n","                cl =  int(np.ceil(x[nbus,t]*(self.dim-1)))\n","                coef = x[nbus,t] * (self.dim-1)-fl\n","                pi0 = pchoice[state[nbus,t] * self.dim + fl,0] * (1-coef) +\\\n","                    pchoice[state[nbus,t] * self.dim + cl,0] *coef\n","                    \n","                action[nbus,t] = np.random.choice([0,1],p=[pi0,1-pi0])\n","                path[0,1] = action[nbus,t]\n","                \n","                if action[nbus,t]==1:\n","                    state[nbus,t+1] = 0\n","                    condition[nbus,t+1] = 0\n","                    path[1,0] = state[nbus,t+1]\n","                else:\n","                    if condition[nbus,t] == 0:\n","                        state[nbus,t+1] = state[nbus,t] + np.random.choice([0,1,2,3],p=[p0[0],p0[1],p0[2],1-np.sum(p0)])\n","                        if state[nbus,t+1]\u003eself.S-1:\n","                            state[nbus,t+1] = self.S-1\n","                            \n","                        condition[nbus,t+1] = np.random.choice([0,1],p=[theta2[0],1-theta2[0]])\n","                        path[1,0] = state[nbus,t+1]  \n","                    else:\n","                        state[nbus,t+1] = state[nbus,t] + np.random.choice([0,1,2,3],p=[p1[0],p1[1],p1[2],1-np.sum(p1)])\n","                        if state[nbus,t+1]\u003eself.S-1:\n","                            state[nbus,t+1] = self.S-1\n","                        condition[nbus,t+1] = np.random.choice([0,1],p=[theta2[1],1-theta2[1]])\n","                        path[1,0] = state[nbus,t+1]\n","                x[nbus,t+1] = self.belief(theta2,p0,p1, path,x[nbus,t] ,data_gene_status = True)[-1]\n","                \n","            fl =  int(np.floor(x[nbus,TimePeriod-1]*(self.dim-1)))\n","            cl =  int(np.ceil(x[nbus,TimePeriod-1]*(self.dim-1)))\n","            coef = x[nbus,TimePeriod-1] * (self.dim-1)-fl\n","            pi0 = pchoice[state[nbus,TimePeriod-1] * self.dim + fl,0] * (1-coef) +\\\n","                pchoice[state[nbus,TimePeriod-1] * self.dim + cl,0] *coef\n","                \n","            action[nbus,TimePeriod-1] = np.random.choice([0,1],p=[pi0,1-pi0])        \n","          \n","        state_new = np.reshape(state,[-1])\n","        action_new = np.reshape(action,[-1])\n","        data = {'state':state_new,'action':action_new}\n","        dat_new = pd.DataFrame(data=data)\n","        \n","        return dat_new,{'state':state,'action':action,'hidden':condition,'belief':x,'pis':pis}\n","    \n","    def myopic_costs(self, params):\n","        \n","        length = self.Dlength\n","        D = self.D\n","        rc = params[0]\n","        thetas = np.array(params[1:])\n","        maint_cost = np.array([np.dot(0.001*D[d][0]*thetas,[D[d][1],1-D[d][1]])\n","                               for d in range(0, length)])\n","        repl_cost = [rc for d in range(0, length)]\n","\n","        return  np.vstack((maint_cost, repl_cost)).T\n","     \n","    def fl_costs(self, params, theta2, p0, p1 ,beta=0.9999, threading = 0.45):#beta=0.95, threading = 5e-4):#beta=0.9999, threading = 3e-3):#\n","\n","        # Initialization of the contraction mapping\n","        #self.EV_myopic =self.myopic_costs(params)\n","        params = np.array(params)/self.alpha\n","        EV_myopic =self.myopic_costs(params)\n","        \n","        EV_new = EV_myopic\n","\n","        EV = np.zeros(EV_new.shape)        \n","        #VError = np.max(abs(EV-EV_new))\n","        VError = np.max(abs(EV-EV_new))/np.max(np.abs(EV))\n","\n","        #print('Initial Error:',VError,np.max(abs(EV_new)))\n","\n","        #self.trans_mat = self.trans(theta2,p0,p1)\n","        trans_mat = self.trans(theta2,p0,p1)\n","        # Contraction mapping Loop\n","        i = 0\n","        length = self.Dlength\n","        \n","        while(VError\u003ethreading):         \n","\n","            EV = EV_new\n","            m = EV.min(1).reshape(length, -1)\n","            #ecost = np.log(np.exp(-EV+m).sum(1) )-m.T+0.5772\n","            ecost = np.log(np.exp(-EV+m).sum(1) )-m.T+0.5772\n","          \n","            futil_maint = np.dot(ecost, trans_mat)\n","            futil_repl = np.dot(ecost, np.vstack((np.zeros((self.dim-1, self.Dlength)),\n","                                    np.ones((1,self.Dlength)),\n","                                    np.zeros((self.Dlength-self.dim, self.Dlength)))))\n","            futil = np.vstack((futil_maint, futil_repl)).T\n","            EV_new = EV_myopic - beta * futil\n","\n","            i +=1\n","            VError = np.max(abs(EV-EV_new))\n","            # print(i,'th Error:',VError,VError/np.max(abs(EV)),np.max(abs(EV_new)))\n","\n","            #VError = np.max(abs(EV-EV_new))/np.max(np.abs(EV))\n","            #print(i,'th Error:',VError,np.max(abs(EV-EV_new)),np.max(abs(EV_new)))\n","\n","            if i\u003e1000:\n","                break\n","            \n","        #print('{}, Eorror:'.format(i),VError,np.max(abs(EV_new)))   \n","\n","        return EV_new\n","\n","    def choice_prob(self, rho, cost_array):\n","        \"\"\"\n","        Returns the probability of each choice for each observed state, \n","        conditional on an array of state/decision costs (generated by the \n","        myopic or forward-looking cost functions)\n","        \"\"\"\n","        cost_array = cost_array/rho\n","        cost = cost_array - cost_array.min(1).reshape(self.Dlength, -1)\n","        #util = np.exp(-cost)\n","        util = np.exp(-cost)\n","        pchoice = util / (np.sum(util, 1).reshape(self.Dlength, -1))\n","\n","        return pchoice\n","   \n","    def loglike2(self,parameters):\n","        if len(parameters)==8:\n","            theta2 = parameters[6:8]\n","        else:\n","            theta2 = self.theta2\n","        \n","        p0 = parameters[0:3]\n","        p1 = parameters[3:6]\n","        \n","        prob0 = np.array([p0[0],p1[0]])\n","        prob1 = np.array([p0[1],p1[1]])\n","        prob2 = np.array([p0[2],p1[2]])\n","\n","        prob3 = 1 - prob0 -prob1 - prob2\n","\n","        mileage = self.exog\n","\n","        if self.hide_state == True:\n","            beli = []\n","            \n","            for i in range(self.nbus):\n","                beli = beli + self.belief(theta2,p0,p1,\n","                                self.data[i*self.time:(i+1)*self.time],self.belief0[i])\n","        else:\n","            beli = [1 for s in range(0,self.N)]\n","        \n","        logprob = 0\n","        for i in range(self.N-1):\n","            x_cur = [beli[i], 1-beli[i]]\n","\n","            if mileage[i+1] - mileage[i] == 0:\n","                try:\n","                    logprob += np.log(np.dot(prob0,x_cur))\n","                except RuntimeWarning:\n","                    logprob += np.log(np.finfo(float).eps)\n","            \n","            elif mileage[i+1] - mileage[i] == 1:\n","                try:\n","                    logprob += np.log(np.dot(prob1,x_cur))\n","                except RuntimeWarning:\n","                    logprob += np.log(np.finfo(float).eps)             \n","\n","            elif mileage[i+1] - mileage[i] == 2:\n","                try:\n","                    logprob += np.log(np.dot(prob2,x_cur))\n","                except RuntimeWarning:\n","                    logprob += np.log(np.finfo(float).eps)\n","\n","            elif mileage[i+1] - mileage[i] == 3:\n","                try:\n","                    logprob += np.log(np.dot(prob3,x_cur))\n","                except RuntimeWarning:\n","                    logprob += np.log(np.finfo(float).eps)\n","\n","        #print(f'current likelihood: {logprob}')\n","\n","        if self.disp_status:\n","            print(parameters,logprob)\n","        return -logprob/self.time/self.nbus\n","\n","    def loglike(self, parameters, p0, p1, theta2):\n","\n","        params = parameters[0:3]\n","        rho = 1\n","\n","        # p0 = self.fitted2.x[0:3]\n","        # p1 = self.fitted2.x[3:6]\n","        # theta2 = self.theta2\n","        # A (length x 1) matrix        \n","         \n","\n","        beli = []\n","        #self.beli = []\n","\n","        for i in range(self.nbus):\n","            beli = beli + self.belief(theta2,p0,p1,\n","                                        self.data[i*self.time:(i+1)*self.time],self.belief0[i])\n","\n","\n","        bool_floor = np.int_(np.floor(np.array(beli)*(self.dim-1)))\n","        bool_ceil = np.int_(np.ceil(np.array(beli)*(self.dim-1)))\n","        bool_non0 = np.where((bool_floor-bool_ceil)!=0)\n","        coef_floor = np.zeros(bool_floor.shape)\n","        coef_floor[bool_non0] = (np.array(beli)*(self.dim-1)-bool_ceil)[bool_non0]/(bool_floor-bool_ceil)[bool_non0]\n","        \n","        choiceProb = self.choice_prob(rho,self.fl_costs(params,theta2,p0,p1)) #states,actions\n","        action = np.int_(self.data[:,1])\n","        statef =  np.int_(self.exog*self.dim+bool_floor)\n","        statec = np.int_(self.exog*self.dim+bool_ceil)\n","        logprob = coef_floor * choiceProb[statef,action] + (1-coef_floor)* choiceProb[statec,action] \n","        \n","        logprob = np.sum(np.log(logprob))\n","        \n","        if self.disp_status:\n","            print(parameters,logprob)\n","\n","        #print(f'current likelihood:{parameters} {logprob}')\n","\n","        return -logprob#/self.time/self.nbus\n","    \n","    \n","    \n","    def fit_likelihood2(self):\n","        \"\"\"\n","        estimate the dynamic(theta 3)\n","        \"\"\"\n","        x0 = np.array([0.039,0.333,0.590,0.181,0.757,0.061,0.949,0.012])\n","        cons= ({'type': 'ineq', 'fun': lambda x: x[0]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[1]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[2]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[3]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[4]-0.001},\\\n","                {'type': 'ineq', 'fun': lambda x: x[5]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[6]},\\\n","                {'type': 'ineq', 'fun': lambda x: x[7]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[0]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[1]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[2]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[3]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[4]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.998-x[5]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.99999-x[6]},\\\n","                {'type': 'ineq', 'fun': lambda x: 0.99999-x[7]},\\\n","                {'type': 'ineq', 'fun': lambda x: 1-x[0]-x[1]-x[2]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: 1-x[3]-x[4]-x[5]-0.001 },\\\n","                {'type': 'ineq', 'fun': lambda x: -3*x[0]-2*x[1]-x[2]+3*x[3]+2*x[4]+x[5] })\n","        self.fitted2 = minimize(\n","            self.loglike2,\n","            x0=x0,#bounds = bounds,\n","            constraints= cons,\n","            options={'disp': True})\n","        if len(x0)==8:\n","            self.theta2 = self.fitted2.x[6:8]\n","        \n","    def fit_likelihood(self, x0=None, bounds=None,p0 =None,p1=None ):\n","        \"\"\"\n","        estimate the reward parameter\n","        \"\"\"\n","        if bounds == None:\n","            bounds = [(1e-6, 100),(1e-6,100),(1e-6,100)]\n","\n","        if x0 == None:\n","            #x0 = [10,1,1,]\n","            #x0 =  [9.36, 0.94, 0.94] # To speed up, choose a closer initial point\n","            #x0 = [0.1, 0.1, 0.1]\n","            x0 = np.array([9.243,0.226,1.164])*self.alpha#[9,0.5,1]\n","        if np.sum(p0==None) and np.sum(p1==None):\n","            p0 = self.fitted2.x[0:3]\n","            p1 = self.fitted2.x[3:6]\n","        theta2 = self.theta2\n","        #theta2 = self.fitted2.x[6:8]\n","        #p0 = [0.03920017, 0.33350266, 0.59020078]\n","        #p1 = [0.18078681, 0.75749297, 0.06072025]\n","        #theta2 = [0.94946915, 0.01199934]\n","        cons= ({'type': 'ineq', 'fun': lambda x: x[2]-x[1] },\\\n","                {'type': 'ineq', 'fun': lambda x: x[0]-1e-6 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[1]-1e-6 },\\\n","                {'type': 'ineq', 'fun': lambda x: x[2]-1e-6 },\\\n","                {'type': 'ineq', 'fun': lambda x: 100-x[0]},\\\n","                {'type': 'ineq', 'fun': lambda x: 100-x[1]},\\\n","                {'type': 'ineq', 'fun': lambda x: 100-x[2]})\n","        self.fitted = minimize(\n","            self.loglike, x0=x0,#bounds = bounds, \n","            constraints= cons, args=(p0, p1, theta2))\n","        \n","        # bounds = [(1e-6,15),(1e-6 ,2),(1e-6 ,2)]\n","        # func = lambda parameters: self. loglike(parameters, p0, p1, theta2)\n","        # self.fitted = opt.brute(func, bounds, Ns = 3) # To speed up, Ns=3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"CxLoRf1G7Gtw"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reminder1: file group4_new_175.csv should be in the same file directory\n","Reminder2: the code will take almost 4 hours\n","-\u003eDate generation\n","        state  action\n","0          14       0\n","1          16       0\n","2          18       0\n","3          20       0\n","4          22       0\n","...       ...     ...\n","299995     40       0\n","299996     41       0\n","299997     42       0\n","299998     43       0\n","299999     44       0\n","\n","[300000 rows x 2 columns] [0. 0. 0. ... 1. 1. 1.]\n","-\u003eEstimation1 x0 known, alpha =  1\n","[9.243 0.226 1.164] -10694.126430952314\n","[9.243 0.226 1.164] -10694.126430952314\n","[9.24300001 0.226      1.164     ] -10694.126430624328\n","[9.243      0.22600001 1.164     ] -10694.126429833788\n","[9.243      0.226      1.16400001] -10694.126431472829\n","[31.25374219 20.76091797 20.76091797] -80318.66796009729\n","[11.44407422  2.2794918   3.1236918 ] -17693.63104780184\n","[9.46310742 0.43134918 1.35996918] -10748.929100806385\n","[9.26501074 0.24653492 1.18359692] -10693.485943882653\n","[9.26501074 0.24653492 1.18359692] -10693.485943882653\n","[9.26501076 0.24653492 1.18359692] -10693.485943298618\n","[9.26501074 0.24653493 1.18359692] -10693.485943063468\n","[9.26501074 0.24653492 1.18359693] -10693.485945432307\n","[86.21186281 15.80179396 15.80179396] -24564.264437952592\n","[16.95969595  1.80206082  2.64541662] -13413.619455071108\n","[10.03447926  0.40208751  1.32977889] -10685.750863718033\n","[10.03447926  0.40208751  1.32977889] -10685.750863718033\n","[10.03447928  0.40208751  1.32977889] -10685.750863763413\n","[10.03447926  0.40208752  1.32977889] -10685.750863209954\n","[10.03447926  0.40208751  1.3297789 ] -10685.75086422582\n","[9.05786289 0.93175148 0.93175148] -10805.81330124914\n","[9.92524448 0.46133055 1.28525942] -10683.86927905853\n","[9.92524448 0.46133055 1.28525942] -10683.86927905853\n","[9.92524449 0.46133055 1.28525942] -10683.869279538805\n","[9.92524448 0.46133057 1.28525942] -10683.869278755115\n","[9.92524448 0.46133055 1.28525944] -10683.869277642721\n","[9.40756419 0.50256706 1.16875687] -10688.99978832007\n","[9.78102314 0.47281869 1.2528028 ] -10683.401318410994\n","[9.78102314 0.47281869 1.2528028 ] -10683.401318410994\n","[9.78102316 0.47281869 1.2528028 ] -10683.401318281232\n","[9.78102314 0.47281871 1.2528028 ] -10683.401318810946\n","[9.78102314 0.47281869 1.25280282] -10683.401318925073\n","[9.62570203 0.42507557 1.21767415] -10682.818424119823\n","[9.62570203 0.42507557 1.21767415] -10682.818424119823\n","[9.62570204 0.42507557 1.21767415] -10682.818424119256\n","[9.62570203 0.42507559 1.21767415] -10682.818424112287\n","[9.62570203 0.42507557 1.21767416] -10682.818423792278\n","[9.73638453 0.42853262 1.24719438] -10682.888002959962\n","[9.67572797 0.42663808 1.23101661] -10682.721385074943\n","[9.67572797 0.42663808 1.23101661] -10682.721385074943\n","[9.67572799 0.42663808 1.23101661] -10682.721385075127\n","[9.67572797 0.42663809 1.23101661] -10682.721385042807\n","[9.67572797 0.42663808 1.23101663] -10682.721384868919\n","[9.77724172 0.4401114  1.25607459] -10683.017596727948\n","[9.7040606  0.4303985  1.23801033] -10682.768313397111\n","[9.6855028  0.42793543 1.23342946] -10682.733677234839\n","[9.67937233 0.42712177 1.2319162 ] -10682.726056604388\n","[9.67708005 0.42681753 1.23135036] -10682.725243730347\n","[9.67610904 0.42668865 1.23111068] -10682.719983497807\n","[9.67610904 0.42668865 1.23111068] -10682.719983497807\n","[9.67610905 0.42668865 1.23111068] -10682.719983498142\n","[9.67610904 0.42668867 1.23111068] -10682.719983465713\n","[9.67610904 0.42668865 1.23111069] -10682.719983292147\n","[9.7598706  0.43785705 1.25235146] -10683.004338780742\n","[9.69813106 0.42962497 1.23669516] -10682.748112519757\n","[9.68433054 0.42778487 1.23319554] -10682.727233237872\n","[9.67943965 0.42713274 1.23195527] -10682.725542477052\n","[9.67726281 0.42684249 1.23140326] -10682.724477683192\n","[9.67639256 0.42672646 1.23118257] -10682.72772663613\n","[9.67613739 0.42669243 1.23111787] -10682.719876796467\n","[9.67613739 0.42669243 1.23111787] -10682.719876796467\n","[9.6761374  0.42669243 1.23111787] -10682.719876796811\n","[9.67613739 0.42669245 1.23111787] -10682.71987676438\n","[9.67613739 0.42669243 1.23111788] -10682.719876590842\n","[9.7597342  0.43691225 1.25297235] -10683.01816761011\n","[9.69782422 0.42934368 1.23678739] -10682.748415396589\n","[9.68421738 0.42768022 1.2332302 ] -10682.727108370593\n","[9.67941499 0.42709313 1.23197472] -10682.725387259983\n","[9.67727786 0.42683186 1.23141602] -10682.724330694109\n","[9.67642039 0.42672703 1.23119185] -10682.72759945316\n","[9.67616569 0.42669589 1.23112526] -10682.719767944089\n","[9.67616569 0.42669589 1.23112526] -10682.719767944089\n","[9.6761657  0.42669589 1.23112526] -10682.719767944443\n","[9.67616569 0.42669591 1.23112526] -10682.719767912005\n","[9.67616569 0.42669589 1.23112528] -10682.719767738512\n","[9.74248409 0.43564794 1.24874868] -10682.962123694038\n","[9.69335396 0.42901607 1.23569287] -10682.749439587173\n","[9.68213831 0.42750211 1.23271242] -10682.72442538913\n","[9.67865787 0.4270323  1.23178753] -10682.728006047975\n","[9.67684274 0.42678729 1.23130518] -10682.725929938959\n","[9.67626784 0.42670968 1.23115241] -10682.7193664907\n","[9.67626784 0.42670968 1.23115241] -10682.7193664907\n","[9.67626785 0.42670968 1.23115241] -10682.719366491077\n","[9.67626784 0.4267097  1.23115241] -10682.719366458647\n","[9.67626784 0.42670968 1.23115242] -10682.71936628533\n","[9.74992639 0.43674588 1.2509937 ] -10683.015924308926\n","[9.69457716 0.42920438 1.23608436] -10682.745630452398\n","[9.68299729 0.42762659 1.23296511] -10682.730684944177\n","[9.6786331  0.42703196 1.23178953] -10682.727991433865\n","[9.67688503 0.42679378 1.23131866] -10682.725734612324\n","[9.67635374 0.42672139 1.23117555] -10682.727835257858\n","[9.67627643 0.42671085 1.23115472] -10682.719332297422\n","[9.67627643 0.42671085 1.23115472] -10682.719332297422\n","[9.67627644 0.42671085 1.23115472] -10682.719332297796\n","[9.67627643 0.42671087 1.23115472] -10682.719332265367\n"]}],"source":["#%%\n","import pickle\n","import os\n","    \n","print('Reminder1: file group4_new_175.csv should be in the same file directory')\n","print('Reminder2: the code will take almost 4 hours')\n","\n","# a dataframe has two columns, named \"state\" and \"action\".    \n","\n","nbus = 3000\n","time = 100\n","dim_x = 100\n","\n","print('-\u003eDate generation')\n","filename = '/content/drive/MyDrive/2020_WINTER/Rust/data_final/table2_sample_final.txt'\n","with open(filename,'rb') as fp:\n","  dat3 = pickle.load(fp)\n","\n","print(dat3['res'][0],dat3['res'][1]['belief'][:,0])\n","\n","data_record = [] \n","data_record.append(dat3['res'])\n","\n","\n","#     #Record in form: \n","# #       theta2, logSigma, theta3, success1, ccp, [Rc,r1,r2], success2\n","\n","alpha_full = np.array([1])\n","for alpha in alpha_full:\n","    print('-\u003eEstimation1 x0 known, alpha = ', alpha)\n","    timeStart = tm.time()\n","    \n","    #Initialize\n","    estimation1 = FullLikelihood(dat3['res'][0],'action','state', dat3['res'][1]['belief'][:,0],\n","                            dim_x =51,dim_z = 175,time = time, nbus = nbus, alpha =alpha,\n","                            hide_state = True, disp_status = True)\n","    # estimation1.fit_likelihood2()\n","    # data_record.append(estimation1.fitted2)\n","    # print(estimation1.fitted2)\n","    estimation1.theta2 = [0.949,0.012]\n","    estimation1.fit_likelihood(p0 = [0.039,0.333,0.590],p1=[0.181,0.757,0.061])\n","    # estimation1.fit_likelihood()\n","    data_record.append(estimation1.fitted)\n","    print(estimation1.fitted)\n","\n","print(data_record)\n","with open(filename+'samplefinaln1_'+str(dim_x)+'_'+str(nbus)+'_'+str(time)+'.txt', \"wb\") as fp:   #Pickling\n","    res = pickle.dump(data_record,fp)   \n","                    "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOwFrgRJyCJrLHl/aTOWFQ7","name":"Copy of Untitled0_alpha0001_table3data.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}